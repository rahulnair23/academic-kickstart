---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Boolean Rules 2"
subtitle: ""
summary: ""
authors: []
tags: []
categories: []
date: 2020-06-24T13:07:13+01:00
lastmod: 2020-06-24T13:07:13+01:00
featured: false
draft: true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

# An extension

Consider the case where we would like to include some user specified information to help (or enforce) the clause generation step. There are many reasons to do so. Users may have some insight on the underlying processes that generates the data that is not adequately captured or conjunctions generated by the model may have errors that need to be corrected. A further practical model is one of "stabilization". Decision rules sets learnt at increments as training data accumulates should have relatively stable rule sets. For example, a model trained on 2018 data should not be vastly different from one trained on 2019 data.

Assume we are given a known set of clauses $U$ where $U\subseteq K$. One way to include this information in the master program as a constraint, i.e.

$$
w_k = 1 \qquad \forall k \in U.
$$
 
However this may be overly restrictive as a hard constraint. You need to account for the possibility that the data may have drifted and new rules may be necessary. A soft constraint involves including it directly in the objective function. In this form, you incur a penalty each time a user-provided rule is violated. So the modified objective looks like:

$$
\min_{\xi, w} \sum_{i\in P} \xi_i + \sum_{i\in Z}\sum_{k\in K_i} w_k +
\color{blue}\underbrace{\color{black}c_u\sum_{k\in U} (1 - w_k)}_{\text{penalize violated user constraints}}
$$

This is like a regularization and $c_u$ is the regularization parameter. Since this objective represents the Hamming loss, $c_u$ can be interpreted as the number of samples that need to be misclassified before a user provided constraint is dropped.
